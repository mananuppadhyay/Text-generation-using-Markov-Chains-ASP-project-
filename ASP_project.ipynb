{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Function to generate table containing frequencies:"
      ],
      "metadata": {
        "id": "PFyQaqiYyFDY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0olUHYvi8HZu",
        "outputId": "d0e8f323-26c5-4e60-bb40-1f7ed6becdb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'The ': {'t': 1}, 'he t': {'h': 1}, 'e th': {'e': 1}, ' the': {'i': 1}, 'thei': {'r': 1}, 'heir': {' ': 1}, 'eir ': {'t': 1}, 'ir t': {'h': 1}, 'r th': {'i': 1}, ' thi': {'s': 1}, 'this': {' ': 1}, 'his ': {'t': 1}, 'is t': {'h': 1}, 's th': {'o': 1}, ' tho': {'s': 1}, 'thos': {'e': 1}}\n"
          ]
        }
      ],
      "source": [
        "def generateTable(data,k=4):\n",
        "    \n",
        "    Table = {}\n",
        "    for i in range(len(data)-k):\n",
        "        \n",
        "        X = data[i:i+k]\n",
        "        Y = data[i+k]\n",
        "        #print(\"X  %s and Y %s  \"%(X,Y))\n",
        "        \n",
        "        if Table.get(X) is None:\n",
        "            Table[X] = {}\n",
        "            Table[X][Y] = 1\n",
        "        else:\n",
        "            if Table[X].get(Y) is None:\n",
        "                Table[X][Y] = 1\n",
        "            else:\n",
        "                Table[X][Y] += 1\n",
        "    \n",
        "    return Table\n",
        "\n",
        "Table = generateTable(\"The their this those\")\n",
        "print(Table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to convert the calculated frequencies into probability"
      ],
      "metadata": {
        "id": "CepgXGfDyD_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convertFreqIntoProb(Table):     \n",
        "    for kx in Table.keys():\n",
        "        s = float(sum(Table[kx].values()))\n",
        "        for k in Table[kx].keys():\n",
        "            Table[kx][k] = Table[kx][k]/s\n",
        "                \n",
        "    return Table\n",
        " \n",
        "Table = convertFreqIntoProb(Table)\n",
        "print(Table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YB72vPH84uO",
        "outputId": "9cc45dc4-e932-422a-d485-3edaa0545eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'The ': {'t': 1.0}, 'he t': {'h': 1.0}, 'e th': {'e': 1.0}, ' the': {'i': 1.0}, 'thei': {'r': 1.0}, 'heir': {' ': 1.0}, 'eir ': {'t': 1.0}, 'ir t': {'h': 1.0}, 'r th': {'i': 1.0}, ' thi': {'s': 1.0}, 'this': {' ': 1.0}, 'his ': {'t': 1.0}, 'is t': {'h': 1.0}, 's th': {'o': 1.0}, ' tho': {'s': 1.0}, 'thos': {'e': 1.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset\n",
        "(motions.txt is a more comprehensive dataset but training that takes time)"
      ],
      "metadata": {
        "id": "K9HCH__ayRC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_path = \"r1.txt\"\n",
        "def load_text(filename):\n",
        "    with open(filename,encoding='utf8') as f:\n",
        "        return f.read().lower()\n",
        "    \n",
        "text = load_text(text_path)\n",
        "print('Loaded the dataset.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXsXJApo-F-F",
        "outputId": "e9eace23-9d03-4e3c-85a8-1dd5c4aaf995"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling the two functions and hence creating a markov chain with probablities"
      ],
      "metadata": {
        "id": "c7UlfChByS4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def MarkovChain(text,k=4):\n",
        "    Table = generateTable(text,k)\n",
        "    Table = convertFreqIntoProb(Table)\n",
        "    return Table\n",
        " \n",
        "model = MarkovChain(text) \n",
        "print('Model Created Successfully!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cPMC7Ve-kBX",
        "outputId": "4dbc77cc-7c93-41fb-a179-312e6199d468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Created Successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to take the last k characters as input and get the predicted next letter"
      ],
      "metadata": {
        "id": "x9pmW3R71vQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sample_next(context,model,k):\n",
        " \n",
        "    context = context[-k:]\n",
        "    if model.get(context) is None:\n",
        "        return \" \"\n",
        "    possible_Chars = list(model[context].keys())\n",
        "    possible_values = list(model[context].values())\n",
        "    \n",
        "    #print(possible_Chars)\n",
        "    #print(possible_values)\n",
        " \n",
        "    return np.random.choice(possible_Chars,p=possible_values)\n",
        " \n",
        "sample_next(\"thei\",model,4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "YeAi48KR-o-Q",
        "outputId": "443dbc75-b599-4e88-e47e-8ee7ec6188b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'r'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictive text generation:"
      ],
      "metadata": {
        "id": "oxsUw7I2ygbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generateText(starting_sent,k,maxLen):\n",
        "    \n",
        "    sentence = starting_sent\n",
        "    ctx = starting_sent[-k:]\n",
        "  \n",
        "    for ix in range(maxLen):\n",
        "      next_prediction = sample_next(ctx,model,k)\n",
        "      sentence += next_prediction\n",
        "      ctx = sentence[-k:]\n",
        "    return sentence\n",
        "    \n",
        " \n",
        "print(\"Function Created Successfully!\")\n",
        " \n",
        "text = generateText(\"is this the wor\",k=4,maxLen=50)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMma_ks1AHNi",
        "outputId": "3724735c-3265-4248-a70a-6cdac72d7b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function Created Successfully!\n",
            "is this the worst?\n",
            "when you mind kat a do.\n",
            "gosh if you.  you.  yo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bbLQN6ln4ruu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}